{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Algorytm YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pobieranie obrazu\n",
    "```\n",
    "git clone https://github.com/JacobKaczmarek/yolo.git\n",
    "cd yolo\n",
    "docker-compose up\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Czym jest algorytm YOLO?\n",
    "Dzisiejszy \"state of the art\" dla rozpoznawania obiektów na zdjęciach. Jest to algorytm który jest w stanie rozpoznawać obiekty z prędkością nawet 45 klatek na sekunde.\n",
    "\n",
    "[video]("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dlaczego YOLO?\n",
    "Dostępne jest wiele algorytmów służących do wykrywania obiektów. Najpopularniejsze z nich to:\n",
    "- fast R-CNN\n",
    "- Retina-Net\n",
    "- Single-Shot MultiBox Detector(SSD)\n",
    "\n",
    "**YOLO** jest jednak najszybszą alternatywą. Jego główną zaletą jest to że algorytm potrzebuje tylko jednego przejscia przez sieć neuronową dla zadanego obrazu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Jak działa YOLO\n",
    "Algorytm ten działa na podstawie regresji. Dla zadanego obrazu zwraca wykryte obiekty wraz z prawdopodobieństwami tego że należą do danej klasy. Jego działanie jest na tyle szybkie że można używać go do płynnej detekcji obiektów na żywo z filmu lub kamery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cechy szczególne\n",
    "- Algorytm używa siatki nałożonej na obraz zamiast przesuwać \"kadr\" krok po kroku. (Tak jak w przypadku Fast R-CNN)\n",
    "- Połączenie problemu klasyfikacji i lokalizacji w jeden problem regresji. Zwracany wektor zawiera prawdopodobieństwa klas oraz koordynaty obiektu.\n",
    "- Bardzo dobra generalizacja.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Działanie algorytmu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "W pierwszym kroku nakładamy na obraz siatkę o wymiarach $SxS$. Na przykład dla $S=4$ otrymujemy $16$ komórek tak jak na obrazku poniżej.\n",
    "\n",
    "![](img/horses-grid.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Następnie dla każda z komórek może zawierać B obiektów (B jest z góry ustaloną niewielką liczbą na przykład 3). Algorytm wykrywa te obiekty i znajduje ich koordynaty. W wyniku tego działania otrzymujemy wektor o długości\n",
    "  \n",
    "$$\n",
    "S * S * (B * (5+C)) \n",
    "$$\n",
    "  \n",
    "Gdzie:   \n",
    "$S$ - rozmiar siatki  \n",
    "$B$ - maksymalna liczba obiektów wewnątrz jednej komórki  \n",
    "$C$ - liczba klas  \n",
    "  \n",
    "Czyli dla każdej komórki powstaje $B$ następujących wektorów które są łączone w jeden wektor wynikowy:\n",
    "  \n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "           p_c \\\\\n",
    "           b_x \\\\\n",
    "           b_y \\\\\n",
    "           b_h \\\\\n",
    "           b_w \\\\\n",
    "           C_1 \\\\\n",
    "           \\ldots \\\\\n",
    "           C_n \\\\\n",
    "         \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](img/horses-boxes.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Intersection Over Union\n",
    "\n",
    "**Intersection Over Union** jest to miara określająca jak dokładnie pokrywają się dwa obszary. Miara ta ma 2 zastosowania, pierwszym jest ocena tego jak dobrze dopasowany jest obszar do obiektu. Drugim zastosowaniem jest stwierdzenie czy 2 obszary dotyczą tego samego obiektu czy nie.  \n",
    "  \n",
    "W wyniku detekcji w większości wypadków otrzymamy więcej niż jeden obszar dotyczący tego samego obiektu. wtedy aby zadecydować który wybrać sortujemy wszystkie detekcje pod kątem prawdopodobieństwa, jeśli **IOU** jest wysokie oznacza to że dotyczą tego samego obiektu i można wybrać ten z najwyższym prawdopodobieństwem."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
